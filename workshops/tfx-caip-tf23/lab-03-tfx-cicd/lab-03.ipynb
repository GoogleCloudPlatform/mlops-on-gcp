{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CI/CD for TFX pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "1.  Develop a CI/CD workflow with Cloud Build to build and deploy machine learning pipeline code.\n",
    "2.  Integrate with Github to trigger workflows with pipeline source code repository changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will walk through authoring a Cloud Build CI/CD workflow that automatically builds and deploys the same TFX pipeline from `lab-02.ipynb`. You will also integrate your workflow with GitHub by setting up a trigger that starts the workflow when a new tag is applied to the GitHub repo hosting the pipeline's code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/home/jupyter/.local/bin:/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# Set `PATH` to include the directory containing TFX CLI.\n",
    "PATH=%env PATH\n",
    "%env PATH=/home/jupyter/.local/bin:{PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFX version: 0.25.0\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import tfx; print('TFX version: {}'.format(tfx.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: this lab was built and tested with the following package versions:\n",
    "\n",
    "`TFX version: 0.25.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) If the TFX version above does not match the lab tested defaults, run the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --user tfx==0.25.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: you may need to restart the kernel to pick up the correct package versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Cloud Build workflow\n",
    "Review the `cloudbuild.yaml` file to understand how the CI/CD workflow is implemented and how environment specific settings are abstracted using **Cloud Build** variables.\n",
    "\n",
    "The **Cloud Build** CI/CD workflow automates the steps you walked through manually during `lab-02`:\n",
    "1. Builds the custom TFX image to be used as a runtime execution environment for TFX components and as the AI Platform Training training container.\n",
    "1. Compiles the pipeline and uploads the pipeline to the KFP environment\n",
    "1. Pushes the custom TFX image to your project's **Container Registry**\n",
    "\n",
    "The **Cloud Build** workflow configuration uses both standard and custom [Cloud Build builders](https://cloud.google.com/cloud-build/docs/cloud-builders). The custom builder encapsulates **TFX CLI**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring environment settings\n",
    "\n",
    "Navigate to [AI Platform Pipelines](https://console.cloud.google.com/ai-platform/pipelines/clusters) page in the Google Cloud Console.\n",
    "\n",
    "**1.  Create or select an existing Kubernetes cluster (GKE) and deploy AI Platform**. Make sure to select `\"Allow access to the following Cloud APIs https://www.googleapis.com/auth/cloud-platform\"` to allow for programmatic access to your pipeline by the Kubeflow SDK for the rest of the lab. Also, provide an `App instance name` such as \"tfx\" or \"mlops\". Note you may have already deployed an AI Pipelines instance during the Setup for the lab series. If so, you can proceed using that instance below in the next step.\n",
    "\n",
    "Validate the deployment of your AI Platform Pipelines instance in the console before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Configuring environment settings**\n",
    "\n",
    "Update  the below constants  with the settings reflecting your lab environment. \n",
    "\n",
    "- `GCP_REGION` - the compute region for AI Platform Training and Prediction\n",
    "- `ARTIFACT_STORE` - the GCS bucket created during installation of AI Platform Pipelines. The bucket name starts with the `kubeflowpipelines-` prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://artifacts.dougkelly-sandbox.appspot.com/\n",
      "gs://dougkelly-sandbox/\n",
      "gs://dougkelly-sandbox-kubeflowpipelines-default/\n",
      "gs://dougkelly-sandbox-msc-demos/\n",
      "gs://dougkelly-sandbox_cloudbuild/\n",
      "gs://msc-bqml-demos/\n",
      "gs://msc-demos/\n"
     ]
    }
   ],
   "source": [
    "# Use the following command to identify the GCS bucket for metadata and pipeline storage.\n",
    "!gsutil ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `ENDPOINT` - set the `ENDPOINT` constant to the endpoint to your AI Platform Pipelines instance. The endpoint to the AI Platform Pipelines instance can be found on the [AI Platform Pipelines](https://console.cloud.google.com/ai-platform/pipelines/clusters) page in the Google Cloud Console. Open the *SETTINGS* for your instance and use the value of the `host` variable in the *Connect to this Kubeflow Pipelines instance from a Python client via Kubeflow Pipelines SKD* section of the *SETTINGS* window. The format is `'....[region].pipelines.googleusercontent.com'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCP_REGION = 'us-central1'\n",
    "ARTIFACT_STORE_URI = 'gs://dougkelly-sandbox-kubeflowpipelines-default'\n",
    "ENDPOINT = '60ff837483ecde05-dot-us-central2.pipelines.googleusercontent.com'\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the TFX CLI builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.  Review the Dockerfile describing the TFX CLI builder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM gcr.io/deeplearning-platform-release/tf2-cpu.2-3\n",
      "COPY requirements.txt .\n",
      "RUN python3 -m pip install -U -r requirements.txt\n",
      "\n",
      "ENTRYPOINT [\"tfx\"]\n"
     ]
    }
   ],
   "source": [
    "!cat tfx-cli/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas>1.0.0\n",
      "tfx==0.25.0\n",
      "kfp==1.0.4\n"
     ]
    }
   ],
   "source": [
    "!cat tfx-cli/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.  Build the image and push it to your project's Container Registry**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the [Cloud Build](https://cloud.google.com/cloud-build/docs/running-builds/start-build-manually#gcloud) gcloud command line reference for builds submit. Your image should follow the format `gcr.io/[PROJECT_ID]/[IMAGE_NAME]:latest`. Note the source code for the tfx-cli is in the directory `./tfx-cli`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME='tfx-cli'\n",
    "TAG='latest'\n",
    "IMAGE_URI='gcr.io/{}/{}:{}'.format(PROJECT_ID, IMAGE_NAME, TAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 4 file(s) totalling 368 bytes before compression.\n",
      "Uploading tarball of [tfx-cli] to [gs://dougkelly-sandbox_cloudbuild/source/1610584820.104544-761156cf31dc48b0a9ad548c00fb2572.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/dougkelly-sandbox/builds/52c733e5-258a-413d-a1c9-8a371551063c].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/52c733e5-258a-413d-a1c9-8a371551063c?project=785833199205].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"52c733e5-258a-413d-a1c9-8a371551063c\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://dougkelly-sandbox_cloudbuild/source/1610584820.104544-761156cf31dc48b0a9ad548c00fb2572.tgz#1610584820494453\n",
      "Copying gs://dougkelly-sandbox_cloudbuild/source/1610584820.104544-761156cf31dc48b0a9ad548c00fb2572.tgz#1610584820494453...\n",
      "/ [1 files][  377.0 B/  377.0 B]                                                \n",
      "Operation completed over 1 objects/377.0 B.                                      \n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  5.632kB\n",
      "Step 1/4 : FROM gcr.io/deeplearning-platform-release/tf2-cpu.2-3\n",
      "latest: Pulling from deeplearning-platform-release/tf2-cpu.2-3\n",
      "f22ccc0b8772: Pulling fs layer\n",
      "3cf8fb62ba5f: Pulling fs layer\n",
      "e80c964ece6a: Pulling fs layer\n",
      "b37f61c40172: Pulling fs layer\n",
      "8c47335e6fbf: Pulling fs layer\n",
      "b4130fb48840: Pulling fs layer\n",
      "2d065d739ca2: Pulling fs layer\n",
      "c785fe321ad3: Pulling fs layer\n",
      "fa18799a91d9: Pulling fs layer\n",
      "956e27097e62: Pulling fs layer\n",
      "ab616973205e: Pulling fs layer\n",
      "28adb37a4160: Pulling fs layer\n",
      "f224a69aa011: Pulling fs layer\n",
      "7f850b9da14b: Pulling fs layer\n",
      "d3078a090cbd: Pulling fs layer\n",
      "5a481cbb57e8: Pulling fs layer\n",
      "234007c5a90e: Pulling fs layer\n",
      "a03c6fd6bc3e: Pulling fs layer\n",
      "ee1287759c0d: Pulling fs layer\n",
      "b37f61c40172: Waiting\n",
      "8c47335e6fbf: Waiting\n",
      "b4130fb48840: Waiting\n",
      "2d065d739ca2: Waiting\n",
      "c785fe321ad3: Waiting\n",
      "fa18799a91d9: Waiting\n",
      "956e27097e62: Waiting\n",
      "28adb37a4160: Waiting\n",
      "f224a69aa011: Waiting\n",
      "7f850b9da14b: Waiting\n",
      "d3078a090cbd: Waiting\n",
      "5a481cbb57e8: Waiting\n",
      "234007c5a90e: Waiting\n",
      "a03c6fd6bc3e: Waiting\n",
      "ee1287759c0d: Waiting\n",
      "ab616973205e: Waiting\n",
      "3cf8fb62ba5f: Verifying Checksum\n",
      "3cf8fb62ba5f: Download complete\n",
      "e80c964ece6a: Verifying Checksum\n",
      "e80c964ece6a: Download complete\n",
      "f22ccc0b8772: Verifying Checksum\n",
      "f22ccc0b8772: Download complete\n",
      "b4130fb48840: Verifying Checksum\n",
      "b4130fb48840: Download complete\n",
      "8c47335e6fbf: Verifying Checksum\n",
      "8c47335e6fbf: Download complete\n",
      "c785fe321ad3: Verifying Checksum\n",
      "c785fe321ad3: Download complete\n",
      "fa18799a91d9: Verifying Checksum\n",
      "fa18799a91d9: Download complete\n",
      "956e27097e62: Verifying Checksum\n",
      "956e27097e62: Download complete\n",
      "2d065d739ca2: Verifying Checksum\n",
      "2d065d739ca2: Download complete\n",
      "28adb37a4160: Verifying Checksum\n",
      "28adb37a4160: Download complete\n",
      "ab616973205e: Verifying Checksum\n",
      "ab616973205e: Download complete\n",
      "7f850b9da14b: Verifying Checksum\n",
      "7f850b9da14b: Download complete\n",
      "f224a69aa011: Verifying Checksum\n",
      "f224a69aa011: Download complete\n",
      "d3078a090cbd: Verifying Checksum\n",
      "d3078a090cbd: Download complete\n",
      "b37f61c40172: Verifying Checksum\n",
      "b37f61c40172: Download complete\n",
      "a03c6fd6bc3e: Verifying Checksum\n",
      "a03c6fd6bc3e: Download complete\n",
      "234007c5a90e: Verifying Checksum\n",
      "234007c5a90e: Download complete\n",
      "ee1287759c0d: Verifying Checksum\n",
      "ee1287759c0d: Download complete\n",
      "f22ccc0b8772: Pull complete\n",
      "3cf8fb62ba5f: Pull complete\n",
      "e80c964ece6a: Pull complete\n",
      "5a481cbb57e8: Verifying Checksum\n",
      "5a481cbb57e8: Download complete\n",
      "b37f61c40172: Pull complete\n",
      "8c47335e6fbf: Pull complete\n",
      "b4130fb48840: Pull complete\n",
      "2d065d739ca2: Pull complete\n",
      "c785fe321ad3: Pull complete\n",
      "fa18799a91d9: Pull complete\n",
      "956e27097e62: Pull complete\n",
      "ab616973205e: Pull complete\n",
      "28adb37a4160: Pull complete\n",
      "f224a69aa011: Pull complete\n",
      "7f850b9da14b: Pull complete\n",
      "d3078a090cbd: Pull complete\n",
      "5a481cbb57e8: Pull complete\n",
      "234007c5a90e: Pull complete\n",
      "a03c6fd6bc3e: Pull complete\n",
      "ee1287759c0d: Pull complete\n",
      "Digest: sha256:596f810faaf0234515ac6a44de1ac7f69961ec2718410431222d2c445fc42a23\n",
      "Status: Downloaded newer image for gcr.io/deeplearning-platform-release/tf2-cpu.2-3:latest\n",
      " ---> 363491690fe6\n",
      "Step 2/4 : COPY requirements.txt .\n",
      " ---> 7e3c4b3b8868\n",
      "Step 3/4 : RUN python3 -m pip install -U -r requirements.txt\n",
      " ---> Running in 978ad56635e9\n",
      "Requirement already satisfied: pandas>1.0.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: tfx==0.25.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (0.25.0)\n",
      "Collecting kfp==1.0.4\n",
      "  Downloading kfp-1.0.4.tar.gz (116 kB)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.4->-r requirements.txt (line 3)) (5.3.1)\n",
      "Requirement already satisfied: google-cloud-storage>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.4->-r requirements.txt (line 3)) (1.30.0)\n",
      "Requirement already satisfied: google-auth>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.4->-r requirements.txt (line 3)) (1.24.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.4->-r requirements.txt (line 3)) (1.6.0)\n",
      "Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.4->-r requirements.txt (line 3)) (3.2.0)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.4->-r requirements.txt (line 3)) (0.8.7)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from kfp==1.0.4->-r requirements.txt (line 3)) (7.1.2)\n",
      "Requirement already satisfied: tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2 in /opt/conda/lib/python3.7/site-packages (from tfx==0.25.0->-r requirements.txt (line 2)) (2.3.1)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in /opt/conda/lib/python3.7/site-packages (from tfx==0.25.0->-r requirements.txt (line 2)) (1.12.8)\n",
      "Requirement already satisfied: tensorflow-model-analysis<0.26,>=0.25 in /opt/conda/lib/python3.7/site-packages (from tfx==0.25.0->-r requirements.txt (line 2)) (0.25.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.12.2 in /opt/conda/lib/python3.7/site-packages (from tfx==0.25.0->-r requirements.txt (line 2)) (3.14.0)\n",
      "Requirement already satisfied: tensorflow-transform<0.26,>=0.25 in /opt/conda/lib/python3.7/site-packages (from tfx==0.25.0->-r requirements.txt (line 2)) (0.25.0)\n",
      "Requirement already satisfied: keras-tuner<2,>=1 in /opt/conda/lib/python3.7/site-packages (from tfx==0.25.0->-r requirements.txt (line 2)) (1.0.2)\n",
      "Requirement already satisfied: tensorflow-data-validation<0.26,>=0.25 in /opt/conda/lib/python3.7/site-packages (from tfx==0.25.0->-r requirements.txt (line 2)) (0.25.0)\n",
      "Requirement already satisfied: apache-beam[gcp]<3,>=2.25 in /opt/conda/lib/python3.7/site-packages (from tfx==0.25.0->-r requirements.txt (line 2)) (2.26.0)\n",
      "Requirement already satisfied: tensorflow-cloud<0.2,>=0.1 in /opt/conda/lib/python3.7/site-packages (from tfx==0.25.0->-r requirements.txt (line 2)) (0.1.7)\n",
      "Requirement already satisfied: ml-metadata<0.26,>=0.25 in /opt/conda/lib/python3.7/site-packages (from tfx==0.25.0->-r requirements.txt (line 2)) (0.25.1)\n",
      "Requirement already satisfied: grpcio<2,>=1.28.1 in /opt/conda/lib/python3.7/site-packages (from tfx==0.25.0->-r requirements.txt (line 2)) (1.34.0)\n",
      "Requirement already satisfied: absl-py<0.11,>=0.9 in /opt/conda/lib/python3.7/site-packages (from tfx==0.25.0->-r requirements.txt (line 2)) (0.10.0)\n",
      "Requirement already satisfied: tfx-bsl<0.26,>=0.25 in /opt/conda/lib/python3.7/site-packages (from tfx==0.25.0->-r requirements.txt (line 2)) (0.25.0)\n",
      "Requirement already satisfied: docker<5,>=4.1 in /opt/conda/lib/python3.7/site-packages (from tfx==0.25.0->-r requirements.txt (line 2)) (4.4.1)\n",
      "Requirement already satisfied: tensorflow-hub<0.10,>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from tfx==0.25.0->-r requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: jinja2<3,>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from tfx==0.25.0->-r requirements.txt (line 2)) (2.11.2)\n",
      "Requirement already satisfied: six<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from tfx==0.25.0->-r requirements.txt (line 2)) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15 in /opt/conda/lib/python3.7/site-packages (from tfx==0.25.0->-r requirements.txt (line 2)) (2.3.0)\n",
      "Requirement already satisfied: attrs<21,>=19.3.0 in /opt/conda/lib/python3.7/site-packages (from tfx==0.25.0->-r requirements.txt (line 2)) (20.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>1.0.0->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>1.0.0->-r requirements.txt (line 1)) (2020.5)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.7/site-packages (from pandas>1.0.0->-r requirements.txt (line 1)) (1.19.5)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.7)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (2.5.8)\n",
      "Requirement already satisfied: fastavro<2,>=0.21.4 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.2.3)\n",
      "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (3.7.4.3)\n",
      "Requirement already satisfied: oauth2client<5,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (4.1.3)\n",
      "Requirement already satisfied: future<1.0.0,>=0.18.2 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.18.2)\n",
      "Requirement already satisfied: avro-python3!=1.9.2,<1.10.0,>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.9.2.1)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (3.11.2)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (2.25.1)\n",
      "Requirement already satisfied: mock<3.0.0,>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (2.0.0)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.3.1.1)\n",
      "Requirement already satisfied: google-cloud-bigtable<2,>=0.31.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: google-cloud-datastore<2,>=1.7.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.12.0)\n",
      "Requirement already satisfied: cachetools<5,>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (4.2.0)\n",
      "Requirement already satisfied: google-cloud-videointelligence<2,>=1.8.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.15.0)\n",
      "Requirement already satisfied: google-cloud-build<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (2.0.0)\n",
      "Requirement already satisfied: google-cloud-dlp<2,>=0.12.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: google-cloud-pubsub<2,>=0.39.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.7.0)\n",
      "Requirement already satisfied: google-cloud-vision<2,>=0.38.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: google-apitools<0.5.32,>=0.5.31 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.5.31)\n",
      "Requirement already satisfied: google-cloud-language<2,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: google-cloud-core<2,>=0.28.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: google-cloud-spanner<2,>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.17.1)\n",
      "Requirement already satisfied: grpcio-gcp<1,>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.2.2)\n",
      "Requirement already satisfied: google-cloud-bigquery<2,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.26.1)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from docker<5,>=4.1->tfx==0.25.0->-r requirements.txt (line 2)) (0.57.0)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->tfx==0.25.0->-r requirements.txt (line 2)) (1.22.4)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->tfx==0.25.0->-r requirements.txt (line 2)) (0.0.4)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->tfx==0.25.0->-r requirements.txt (line 2)) (3.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->tfx==0.25.0->-r requirements.txt (line 2)) (1.52.0)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->tfx==0.25.0->-r requirements.txt (line 2)) (51.1.1)\n",
      "Requirement already satisfied: fasteners>=0.14 in /opt/conda/lib/python3.7/site-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.16)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==1.0.4->-r requirements.txt (line 3)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==1.0.4->-r requirements.txt (line 3)) (4.6)\n",
      "Requirement already satisfied: google-resumable-media<2.0dev,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<2,>=1.6.0->apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<0.13dev,>=0.12.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigtable<2,>=0.31.1->apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.12.3)\n",
      "Requirement already satisfied: libcst>=0.2.5 in /opt/conda/lib/python3.7/site-packages (from google-cloud-build<3,>=2.0.0->apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.3.16)\n",
      "Requirement already satisfied: proto-plus>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-build<3,>=2.0.0->apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.13.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<2.0dev,>=0.5.0->google-cloud-bigquery<2,>=1.6.0->apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.5.0->google-cloud-bigquery<2,>=1.6.0->apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.14.4)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.5.0->google-cloud-bigquery<2,>=1.6.0->apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (2.20)\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.6.2)\n",
      "Collecting httplib2<0.18.0,>=0.8\n",
      "  Downloading httplib2-0.17.4-py3-none-any.whl (95 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2<3,>=2.7.3->tfx==0.25.0->-r requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kfp==1.0.4->-r requirements.txt (line 3)) (3.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kfp==1.0.4->-r requirements.txt (line 3)) (0.17.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from keras-tuner<2,>=1->tfx==0.25.0->-r requirements.txt (line 2)) (0.24.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from keras-tuner<2,>=1->tfx==0.25.0->-r requirements.txt (line 2)) (4.55.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from keras-tuner<2,>=1->tfx==0.25.0->-r requirements.txt (line 2)) (20.8)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from keras-tuner<2,>=1->tfx==0.25.0->-r requirements.txt (line 2)) (0.4.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from keras-tuner<2,>=1->tfx==0.25.0->-r requirements.txt (line 2)) (1.6.0)\n",
      "Requirement already satisfied: terminaltables in /opt/conda/lib/python3.7/site-packages (from keras-tuner<2,>=1->tfx==0.25.0->-r requirements.txt (line 2)) (3.1.0)\n",
      "Collecting kfp-server-api<2.0.0,>=0.2.5\n",
      "  Downloading kfp-server-api-1.3.0.tar.gz (54 kB)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=0.2.5->kfp==1.0.4->-r requirements.txt (line 3)) (1.26.2)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=0.2.5->kfp==1.0.4->-r requirements.txt (line 3)) (2020.12.5)\n",
      "Collecting kubernetes<12.0.0,>=8.0.0\n",
      "  Downloading kubernetes-11.0.0-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<12.0.0,>=8.0.0->kfp==1.0.4->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from libcst>=0.2.5->google-cloud-build<3,>=2.0.0->apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.6.0)\n",
      "Requirement already satisfied: pbr>=0.11 in /opt/conda/lib/python3.7/site-packages (from mock<3.0.0,>=1.0.1->apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (5.5.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.7/site-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.4.8)\n",
      "Collecting pyarrow<0.18,>=0.17\n",
      "  Downloading pyarrow-0.17.1-cp37-cp37m-manylinux2014_x86_64.whl (63.8 MB)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /opt/conda/lib/python3.7/site-packages (from pydot<2,>=1.2.0->apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (2.10)\n",
      "Collecting requests_toolbelt>=0.8.0\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->tfx==0.25.0->-r requirements.txt (line 2)) (0.36.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->tfx==0.25.0->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->tfx==0.25.0->-r requirements.txt (line 2)) (2.3.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->tfx==0.25.0->-r requirements.txt (line 2)) (2.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->tfx==0.25.0->-r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->tfx==0.25.0->-r requirements.txt (line 2)) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->tfx==0.25.0->-r requirements.txt (line 2)) (2.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->tfx==0.25.0->-r requirements.txt (line 2)) (1.12.1)\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->tfx==0.25.0->-r requirements.txt (line 2)) (0.3.3)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->tfx==0.25.0->-r requirements.txt (line 2)) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->tfx==0.25.0->-r requirements.txt (line 2)) (3.3.0)\n",
      "Collecting numpy>=1.16.5\n",
      "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->tfx==0.25.0->-r requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->tfx==0.25.0->-r requirements.txt (line 2)) (0.4.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->tfx==0.25.0->-r requirements.txt (line 2)) (3.3.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15.2->tfx==0.25.0->-r requirements.txt (line 2)) (1.7.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<12.0.0,>=8.0.0->kfp==1.0.4->-r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: tensorflow-datasets<3.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-cloud<0.2,>=0.1->tfx==0.25.0->-r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: tensorflow-metadata<0.26,>=0.25 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.25.0)\n",
      "Collecting joblib<0.15,>=0.12\n",
      "  Downloading joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
      "Requirement already satisfied: promise in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets<3.1.0->tensorflow-cloud<0.2,>=0.1->tfx==0.25.0->-r requirements.txt (line 2)) (2.3)\n",
      "Requirement already satisfied: ipython<8,>=7 in /opt/conda/lib/python3.7/site-packages (from tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (7.19.0)\n",
      "Requirement already satisfied: ipywidgets<8,>=7 in /opt/conda/lib/python3.7/site-packages (from tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (7.6.2)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (4.4.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (2.7.3)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.18.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (5.0.5)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (3.0.9)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (5.3.4)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (3.5.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (5.0.8)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (6.1)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (6.1.7)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->ipython<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.8.1)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (4.7.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.2.5)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from typing-inspect>=0.4.0->libcst>=0.2.5->google-cloud-build<3,>=2.0.0->apache-beam[gcp]<3,>=2.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.4.3)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (6.1.6)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (6.0.7)\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.9.2)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (20.1.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (20.0.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.9.0)\n",
      "Collecting Deprecated\n",
      "  Downloading Deprecated-1.2.10-py2.py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonschema>=3.0.1->kfp==1.0.4->-r requirements.txt (line 3)) (3.4.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.1.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.4.2)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.4.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.3)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.6.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.5.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.8.4)\n",
      "Requirement already satisfied: async-generator in /opt/conda/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (1.4.3)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.26,>=0.25->tfx==0.25.0->-r requirements.txt (line 2)) (0.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->keras-tuner<2,>=1->tfx==0.25.0->-r requirements.txt (line 2)) (2.1.0)\n",
      "Collecting strip-hints\n",
      "  Downloading strip-hints-0.1.9.tar.gz (30 kB)\n",
      "Building wheels for collected packages: kfp, kfp-server-api, strip-hints\n",
      "  Building wheel for kfp (setup.py): started\n",
      "  Building wheel for kfp (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp: filename=kfp-1.0.4-py3-none-any.whl size=159872 sha256=4eb0dc99cfb0db812199df3a4a122e4150a6b8dc2053a2a131f17188ef0b4e85\n",
      "  Stored in directory: /root/.cache/pip/wheels/65/1c/be/3d7366d2288bf1587e4fe6cd0c1ebdce5e3bada21b70a29e66\n",
      "  Building wheel for kfp-server-api (setup.py): started\n",
      "  Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp-server-api: filename=kfp_server_api-1.3.0-py3-none-any.whl size=108020 sha256=ed3585c01d4ed3236daa1562efca87c7a1b337c6a0475f2f7cc82b06d9151108\n",
      "  Stored in directory: /root/.cache/pip/wheels/40/c1/57/7c3f9134d56eda563ad945a904e9e2edbd22479b292558659e\n",
      "  Building wheel for strip-hints (setup.py): started\n",
      "  Building wheel for strip-hints (setup.py): finished with status 'done'\n",
      "  Created wheel for strip-hints: filename=strip_hints-0.1.9-py2.py3-none-any.whl size=20993 sha256=4af843d163d27e65026d52b1bcc06f9e6d6700b67ff49a3f90fa95e77b2a961d\n",
      "  Stored in directory: /root/.cache/pip/wheels/2d/b8/4e/a3ec111d2db63cec88121bd7c0ab1a123bce3b55dd19dda5c1\n",
      "Successfully built kfp kfp-server-api strip-hints\n",
      "Installing collected packages: numpy, httplib2, pyarrow, joblib, strip-hints, requests-toolbelt, kubernetes, kfp-server-api, Deprecated, kfp\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "\u001b[1;33mWARNING:\u001b[0m Reading GCS logfile: got 503, retrying\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: httplib2\n",
      "    Found existing installation: httplib2 0.18.1\n",
      "    Uninstalling httplib2-0.18.1:\n",
      "      Successfully uninstalled httplib2-0.18.1\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 2.0.0\n",
      "    Uninstalling pyarrow-2.0.0:\n",
      "      Successfully uninstalled pyarrow-2.0.0\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.0.0\n",
      "    Uninstalling joblib-1.0.0:\n",
      "      Successfully uninstalled joblib-1.0.0\n",
      "  Attempting uninstall: kubernetes\n",
      "    Found existing installation: kubernetes 12.0.1\n",
      "    Uninstalling kubernetes-12.0.1:\n",
      "      Successfully uninstalled kubernetes-12.0.1\n",
      "\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-probability 0.11.0 requires cloudpickle==1.3, but you have cloudpickle 1.6.0 which is incompatible.\n",
      "pandas-profiling 2.8.0 requires visions[type_image_path]==0.4.4, but you have visions 0.7.0 which is incompatible.\n",
      "cloud-tpu-client 0.10 requires google-api-python-client==1.8.0, but you have google-api-python-client 1.12.8 which is incompatible.\n",
      "\u001b[0mSuccessfully installed Deprecated-1.2.10 httplib2-0.17.4 joblib-0.14.1 kfp-1.0.4 kfp-server-api-1.3.0 kubernetes-11.0.0 numpy-1.18.5 pyarrow-0.17.1 requests-toolbelt-0.9.1 strip-hints-0.1.9\n",
      "Removing intermediate container 978ad56635e9\n",
      " ---> 2eb3ea282878\n",
      "Step 4/4 : ENTRYPOINT [\"tfx\"]\n",
      " ---> Running in b7e0e7919691\n",
      "Removing intermediate container b7e0e7919691\n",
      " ---> 34c9d6b0768f\n",
      "Successfully built 34c9d6b0768f\n",
      "Successfully tagged gcr.io/dougkelly-sandbox/tfx-cli:latest\n",
      "PUSH\n",
      "Pushing gcr.io/dougkelly-sandbox/tfx-cli:latest\n",
      "The push refers to repository [gcr.io/dougkelly-sandbox/tfx-cli]\n",
      "4ec0ce162d06: Preparing\n",
      "fbc42730c887: Preparing\n",
      "49ab78b19e90: Preparing\n",
      "b35688337021: Preparing\n",
      "29d20189160e: Preparing\n",
      "c98f8d2ccd34: Preparing\n",
      "adbb2d670f70: Preparing\n",
      "f7ad18e63dd1: Preparing\n",
      "ad1c977db453: Preparing\n",
      "0213dad8c5b8: Preparing\n",
      "e81f8f5513be: Preparing\n",
      "1a38e8b065db: Preparing\n",
      "515efe70ac06: Preparing\n",
      "e9b2f435d0f4: Preparing\n",
      "921c1d915c8a: Preparing\n",
      "5eade5acc0d1: Preparing\n",
      "d58735f9e335: Preparing\n",
      "1fc64be52986: Preparing\n",
      "fe6d8881187d: Preparing\n",
      "23135df75b44: Preparing\n",
      "b43408d5f11b: Preparing\n",
      "c98f8d2ccd34: Waiting\n",
      "adbb2d670f70: Waiting\n",
      "f7ad18e63dd1: Waiting\n",
      "ad1c977db453: Waiting\n",
      "0213dad8c5b8: Waiting\n",
      "e81f8f5513be: Waiting\n",
      "1a38e8b065db: Waiting\n",
      "515efe70ac06: Waiting\n",
      "e9b2f435d0f4: Waiting\n",
      "921c1d915c8a: Waiting\n",
      "5eade5acc0d1: Waiting\n",
      "d58735f9e335: Waiting\n",
      "1fc64be52986: Waiting\n",
      "fe6d8881187d: Waiting\n",
      "23135df75b44: Waiting\n",
      "b43408d5f11b: Waiting\n",
      "29d20189160e: Layer already exists\n",
      "b35688337021: Layer already exists\n",
      "49ab78b19e90: Layer already exists\n",
      "c98f8d2ccd34: Layer already exists\n",
      "f7ad18e63dd1: Layer already exists\n",
      "adbb2d670f70: Layer already exists\n",
      "ad1c977db453: Layer already exists\n",
      "e81f8f5513be: Layer already exists\n",
      "0213dad8c5b8: Layer already exists\n",
      "1a38e8b065db: Layer already exists\n",
      "515efe70ac06: Layer already exists\n",
      "e9b2f435d0f4: Layer already exists\n",
      "921c1d915c8a: Layer already exists\n",
      "5eade5acc0d1: Layer already exists\n",
      "d58735f9e335: Layer already exists\n",
      "fbc42730c887: Pushed\n",
      "1fc64be52986: Layer already exists\n",
      "fe6d8881187d: Layer already exists\n",
      "23135df75b44: Layer already exists\n",
      "b43408d5f11b: Layer already exists\n",
      "4ec0ce162d06: Pushed\n",
      "latest: digest: sha256:f0554ac7a9cb2e8fa3a0987e7255af8aae3b78e69133d61fa51e49715304164e size: 4718\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                           IMAGES                                      STATUS\n",
      "52c733e5-258a-413d-a1c9-8a371551063c  2021-01-14T00:40:20+00:00  3M48S     gs://dougkelly-sandbox_cloudbuild/source/1610584820.104544-761156cf31dc48b0a9ad548c00fb2572.tgz  gcr.io/dougkelly-sandbox/tfx-cli (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --timeout=15m --tag {IMAGE_URI} tfx-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: manually trigger CI/CD pipeline run with Cloud Build\n",
    "\n",
    "You can manually trigger **Cloud Build** runs using the `gcloud builds submit` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME='tfx_covertype_continuous_training'\n",
    "TAG_NAME='test'\n",
    "TFX_IMAGE_NAME='lab-03-tfx-image'\n",
    "DATA_ROOT_URI='gs://workshop-datasets/covertype/small'\n",
    "MODEL_NAME='tfx_covertype_classifier'\n",
    "PIPELINE_FOLDER='pipeline'\n",
    "PIPELINE_DSL='runner.py'\n",
    "RUNTIME_VERSION='2.3'\n",
    "PYTHON_VERSION='3.7'\n",
    "USE_KFP_SA='False'\n",
    "\n",
    "SUBSTITUTIONS=\"\"\"\n",
    "_ENDPOINT={},\\\n",
    "_GCP_REGION={},\\\n",
    "_ARTIFACT_STORE_URI={},\\\n",
    "_TFX_IMAGE_NAME={},\\\n",
    "_DATA_ROOT_URI={},\\\n",
    "_MODEL_NAME={},\\\n",
    "TAG_NAME={},\\\n",
    "_PIPELINE_FOLDER={},\\\n",
    "_PIPELINE_DSL={},\\\n",
    "_PIPELINE_NAME={},\\\n",
    "_RUNTIME_VERSION={},\\\n",
    "_USE_KFP_SA={},\\\n",
    "_PYTHON_VERSION={}\n",
    "\"\"\".format(ENDPOINT, \n",
    "           GCP_REGION, \n",
    "           ARTIFACT_STORE_URI, \n",
    "           TFX_IMAGE_NAME,\n",
    "           DATA_ROOT_URI,\n",
    "           MODEL_NAME,\n",
    "           TAG_NAME, \n",
    "           PIPELINE_FOLDER,\n",
    "           PIPELINE_DSL,\n",
    "           PIPELINE_NAME,\n",
    "           RUNTIME_VERSION,\n",
    "           PYTHON_VERSION,\n",
    "           USE_KFP_SA\n",
    "           ).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: you can manually trigger **Cloud Build** runs using the `gcloud builds submit` command. See the [documentation](https://cloud.google.com/sdk/gcloud/reference/builds/submit) for pass the `cloudbuild.yaml` file and SUBSTITIONS as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 38 file(s) totalling 262.3 KiB before compression.\n",
      "Uploading tarball of [.] to [gs://dougkelly-sandbox_cloudbuild/source/1610672991.449488-8203b5f3502b497abd585ba9e6a57b87.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/dougkelly-sandbox/builds/acff2fc6-1cd8-43c7-b7e8-4682d8f3bcd7].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/acff2fc6-1cd8-43c7-b7e8-4682d8f3bcd7?project=785833199205].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"acff2fc6-1cd8-43c7-b7e8-4682d8f3bcd7\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://dougkelly-sandbox_cloudbuild/source/1610672991.449488-8203b5f3502b497abd585ba9e6a57b87.tgz#1610672991901544\n",
      "Copying gs://dougkelly-sandbox_cloudbuild/source/1610672991.449488-8203b5f3502b497abd585ba9e6a57b87.tgz#1610672991901544...\n",
      "/ [1 files][ 53.3 KiB/ 53.3 KiB]                                                \n",
      "Operation completed over 1 objects/53.3 KiB.                                     \n",
      "BUILD\n",
      "Starting Step #0\n",
      "Step #0: Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Step #0: Sending build context to Docker daemon  87.04kB\n",
      "Step #0: Step 1/4 : FROM tensorflow/tfx:0.25.0\n",
      "Step #0: 0.25.0: Pulling from tensorflow/tfx\n",
      "Step #0: bd47987755ba: Pulling fs layer\n",
      "Step #0: 831c222b21d8: Pulling fs layer\n",
      "Step #0: 3c2cba919283: Pulling fs layer\n",
      "Step #0: e378d88a5f59: Pulling fs layer\n",
      "Step #0: df37508d2f5c: Pulling fs layer\n",
      "Step #0: c28e7cc900d1: Pulling fs layer\n",
      "Step #0: 9019978541a7: Pulling fs layer\n",
      "Step #0: 80dc388c898c: Pulling fs layer\n",
      "Step #0: afebcf787e04: Pulling fs layer\n",
      "Step #0: b32cc9704312: Pulling fs layer\n",
      "Step #0: a0336ba74309: Pulling fs layer\n",
      "Step #0: e378d88a5f59: Waiting\n",
      "Step #0: df37508d2f5c: Waiting\n",
      "Step #0: c28e7cc900d1: Waiting\n",
      "Step #0: 9019978541a7: Waiting\n",
      "Step #0: 80dc388c898c: Waiting\n",
      "Step #0: afebcf787e04: Waiting\n",
      "Step #0: b32cc9704312: Waiting\n",
      "Step #0: a0336ba74309: Waiting\n",
      "Step #0: 3c2cba919283: Verifying Checksum\n",
      "Step #0: 3c2cba919283: Download complete\n",
      "Step #0: 831c222b21d8: Verifying Checksum\n",
      "Step #0: 831c222b21d8: Download complete\n",
      "Step #0: bd47987755ba: Verifying Checksum\n",
      "Step #0: bd47987755ba: Download complete\n",
      "Step #0: c28e7cc900d1: Verifying Checksum\n",
      "Step #0: c28e7cc900d1: Download complete\n",
      "Step #0: 9019978541a7: Verifying Checksum\n",
      "Step #0: 9019978541a7: Download complete\n",
      "Step #0: e378d88a5f59: Verifying Checksum\n",
      "Step #0: e378d88a5f59: Download complete\n",
      "Step #0: df37508d2f5c: Verifying Checksum\n",
      "Step #0: df37508d2f5c: Download complete\n",
      "Step #0: afebcf787e04: Verifying Checksum\n",
      "Step #0: afebcf787e04: Download complete\n",
      "Step #0: a0336ba74309: Verifying Checksum\n",
      "Step #0: a0336ba74309: Download complete\n",
      "Step #0: bd47987755ba: Pull complete\n",
      "Step #0: 831c222b21d8: Pull complete\n",
      "Step #0: 3c2cba919283: Pull complete\n",
      "Step #0: b32cc9704312: Verifying Checksum\n",
      "Step #0: b32cc9704312: Download complete\n",
      "Step #0: 80dc388c898c: Verifying Checksum\n",
      "Step #0: 80dc388c898c: Download complete\n",
      "Step #0: e378d88a5f59: Pull complete\n",
      "Step #0: df37508d2f5c: Pull complete\n",
      "Step #0: c28e7cc900d1: Pull complete\n",
      "Step #0: 9019978541a7: Pull complete\n",
      "Step #0: 80dc388c898c: Pull complete\n",
      "Step #0: afebcf787e04: Pull complete\n",
      "Step #0: b32cc9704312: Pull complete\n",
      "Step #0: a0336ba74309: Pull complete\n",
      "Step #0: Digest: sha256:0700c27c6492b8b2998e7d543ca13088db8d40ef26bd5c6eec58245ff8cdec35\n",
      "Step #0: Status: Downloaded newer image for tensorflow/tfx:0.25.0\n",
      "Step #0:  ---> 05d9b228cf63\n",
      "Step #0: Step 2/4 : WORKDIR ./pipeline\n",
      "Step #0:  ---> Running in 99257697e5ec\n",
      "Step #0: Removing intermediate container 99257697e5ec\n",
      "Step #0:  ---> b462be0a7d44\n",
      "Step #0: Step 3/4 : COPY ./ ./\n",
      "Step #0:  ---> bd22fb400c65\n",
      "Step #0: Step 4/4 : ENV PYTHONPATH=\"/pipeline:${PYTHONPATH}\"\n",
      "Step #0:  ---> Running in c214dd0e53b7\n",
      "Step #0: Removing intermediate container c214dd0e53b7\n",
      "Step #0:  ---> a867dd2f1d7f\n",
      "Step #0: Successfully built a867dd2f1d7f\n",
      "Step #0: Successfully tagged gcr.io/dougkelly-sandbox/lab-03-tfx-image:test2\n",
      "Finished Step #0\n",
      "Starting Step #1\n",
      "Step #1: Pulling image: gcr.io/dougkelly-sandbox/tfx-cli\n",
      "Step #1: Using default tag: latest\n",
      "Step #1: latest: Pulling from dougkelly-sandbox/tfx-cli\n",
      "Step #1: f22ccc0b8772: Pulling fs layer\n",
      "Step #1: 3cf8fb62ba5f: Pulling fs layer\n",
      "Step #1: e80c964ece6a: Pulling fs layer\n",
      "Step #1: b37f61c40172: Pulling fs layer\n",
      "Step #1: 8c47335e6fbf: Pulling fs layer\n",
      "Step #1: b4130fb48840: Pulling fs layer\n",
      "Step #1: 2d065d739ca2: Pulling fs layer\n",
      "Step #1: c785fe321ad3: Pulling fs layer\n",
      "Step #1: fa18799a91d9: Pulling fs layer\n",
      "Step #1: 956e27097e62: Pulling fs layer\n",
      "Step #1: ab616973205e: Pulling fs layer\n",
      "Step #1: 28adb37a4160: Pulling fs layer\n",
      "Step #1: f224a69aa011: Pulling fs layer\n",
      "Step #1: 7f850b9da14b: Pulling fs layer\n",
      "Step #1: d3078a090cbd: Pulling fs layer\n",
      "Step #1: 5a481cbb57e8: Pulling fs layer\n",
      "Step #1: 234007c5a90e: Pulling fs layer\n",
      "Step #1: a03c6fd6bc3e: Pulling fs layer\n",
      "Step #1: ee1287759c0d: Pulling fs layer\n",
      "Step #1: 5c9ecdb2e2c5: Pulling fs layer\n",
      "Step #1: 5aee7916a865: Pulling fs layer\n",
      "Step #1: b37f61c40172: Waiting\n",
      "Step #1: 8c47335e6fbf: Waiting\n",
      "Step #1: b4130fb48840: Waiting\n",
      "Step #1: 2d065d739ca2: Waiting\n",
      "Step #1: c785fe321ad3: Waiting\n",
      "Step #1: fa18799a91d9: Waiting\n",
      "Step #1: 956e27097e62: Waiting\n",
      "Step #1: ab616973205e: Waiting\n",
      "Step #1: 28adb37a4160: Waiting\n",
      "Step #1: f224a69aa011: Waiting\n",
      "Step #1: 7f850b9da14b: Waiting\n",
      "Step #1: d3078a090cbd: Waiting\n",
      "Step #1: 5a481cbb57e8: Waiting\n",
      "Step #1: 234007c5a90e: Waiting\n",
      "Step #1: a03c6fd6bc3e: Waiting\n",
      "Step #1: ee1287759c0d: Waiting\n",
      "Step #1: 5c9ecdb2e2c5: Waiting\n",
      "Step #1: 5aee7916a865: Waiting\n",
      "Step #1: 3cf8fb62ba5f: Verifying Checksum\n",
      "Step #1: 3cf8fb62ba5f: Download complete\n",
      "Step #1: e80c964ece6a: Verifying Checksum\n",
      "Step #1: e80c964ece6a: Download complete\n",
      "Step #1: f22ccc0b8772: Verifying Checksum\n",
      "Step #1: f22ccc0b8772: Download complete\n",
      "Step #1: b4130fb48840: Verifying Checksum\n",
      "Step #1: b4130fb48840: Download complete\n",
      "Step #1: 8c47335e6fbf: Verifying Checksum\n",
      "Step #1: 8c47335e6fbf: Download complete\n",
      "Step #1: c785fe321ad3: Verifying Checksum\n",
      "Step #1: c785fe321ad3: Download complete\n",
      "Step #1: fa18799a91d9: Verifying Checksum\n",
      "Step #1: fa18799a91d9: Download complete\n",
      "Step #1: 956e27097e62: Verifying Checksum\n",
      "Step #1: 956e27097e62: Download complete\n",
      "Step #1: 2d065d739ca2: Verifying Checksum\n",
      "Step #1: 2d065d739ca2: Download complete\n",
      "Step #1: ab616973205e: Verifying Checksum\n",
      "Step #1: ab616973205e: Download complete\n",
      "Step #1: 28adb37a4160: Verifying Checksum\n",
      "Step #1: 28adb37a4160: Download complete\n",
      "Step #1: f224a69aa011: Verifying Checksum\n",
      "Step #1: f224a69aa011: Download complete\n",
      "Step #1: 7f850b9da14b: Verifying Checksum\n",
      "Step #1: 7f850b9da14b: Download complete\n",
      "Step #1: b37f61c40172: Verifying Checksum\n",
      "Step #1: b37f61c40172: Download complete\n",
      "Step #1: d3078a090cbd: Verifying Checksum\n",
      "Step #1: d3078a090cbd: Download complete\n",
      "Step #1: a03c6fd6bc3e: Verifying Checksum\n",
      "Step #1: a03c6fd6bc3e: Download complete\n",
      "Step #1: ee1287759c0d: Verifying Checksum\n",
      "Step #1: ee1287759c0d: Download complete\n",
      "Step #1: 234007c5a90e: Verifying Checksum\n",
      "Step #1: 234007c5a90e: Download complete\n",
      "Step #1: 5c9ecdb2e2c5: Verifying Checksum\n",
      "Step #1: 5c9ecdb2e2c5: Download complete\n",
      "Step #1: f22ccc0b8772: Pull complete\n",
      "Step #1: 3cf8fb62ba5f: Pull complete\n",
      "Step #1: e80c964ece6a: Pull complete\n",
      "Step #1: 5aee7916a865: Verifying Checksum\n",
      "Step #1: 5aee7916a865: Download complete\n",
      "Step #1: 5a481cbb57e8: Verifying Checksum\n",
      "Step #1: 5a481cbb57e8: Download complete\n",
      "Step #1: b37f61c40172: Pull complete\n",
      "Step #1: 8c47335e6fbf: Pull complete\n",
      "Step #1: b4130fb48840: Pull complete\n",
      "Step #1: 2d065d739ca2: Pull complete\n",
      "Step #1: c785fe321ad3: Pull complete\n",
      "Step #1: fa18799a91d9: Pull complete\n",
      "Step #1: 956e27097e62: Pull complete\n",
      "Step #1: ab616973205e: Pull complete\n",
      "Step #1: 28adb37a4160: Pull complete\n",
      "Step #1: f224a69aa011: Pull complete\n",
      "Step #1: 7f850b9da14b: Pull complete\n",
      "Step #1: d3078a090cbd: Pull complete\n",
      "Step #1: 5a481cbb57e8: Pull complete\n",
      "Step #1: 234007c5a90e: Pull complete\n",
      "Step #1: a03c6fd6bc3e: Pull complete\n",
      "Step #1: ee1287759c0d: Pull complete\n",
      "Step #1: 5c9ecdb2e2c5: Pull complete\n",
      "Step #1: 5aee7916a865: Pull complete\n",
      "Step #1: Digest: sha256:f0554ac7a9cb2e8fa3a0987e7255af8aae3b78e69133d61fa51e49715304164e\n",
      "Step #1: Status: Downloaded newer image for gcr.io/dougkelly-sandbox/tfx-cli:latest\n",
      "Step #1: gcr.io/dougkelly-sandbox/tfx-cli:latest\n",
      "Step #1: CLI\n",
      "Step #1: Creating pipeline\n",
      "Step #1: New container image is built. Target image is available in the build spec file.\n",
      "Step #1: WARNING:absl:RuntimeParameter is only supported on Cloud-based DAG runner currently.\n",
      "Step #1: WARNING:absl:RuntimeParameter is only supported on Cloud-based DAG runner currently.\n",
      "Step #1: WARNING:absl:RuntimeParameter is only supported on Cloud-based DAG runner currently.\n",
      "Step #1: WARNING:absl:RuntimeParameter is only supported on Cloud-based DAG runner currently.\n",
      "Step #1: WARNING:absl:RuntimeParameter is only supported on Cloud-based DAG runner currently.\n",
      "Step #1: WARNING:absl:`instance_name` is deprecated, please set node id directly using`with_id()` or `.id` setter.\n",
      "Step #1: WARNING:absl:`instance_name` is deprecated, please set node id directly using`with_id()` or `.id` setter.\n",
      "Step #1: Pipeline compiled successfully.\n",
      "Step #1: Pipeline package path: /workspace/pipeline/tfx_covertype_continuous_training-test2.tar.gz\n",
      "Step #1: {'created_at': datetime.datetime(2021, 1, 15, 1, 14, 56, tzinfo=tzlocal()),\n",
      "Step #1:  'default_version': {'code_source_url': None,\n",
      "Step #1:                      'created_at': datetime.datetime(2021, 1, 15, 1, 14, 56, tzinfo=tzlocal()),\n",
      "Step #1:                      'id': '59cae7e3-eb4a-4c04-bb71-1689808ecadd',\n",
      "Step #1:                      'name': 'tfx_covertype_continuous_training-test2',\n",
      "Step #1:                      'package_url': None,\n",
      "Step #1:                      'parameters': [{'name': 'pipeline-root',\n",
      "Step #1:                                      'value': 'gs://dougkelly-sandbox-kubeflowpipelines-default/tfx_covertype_continuous_training-test2/{{workflow.uid}}'},\n",
      "Step #1:                                     {'name': 'data-root-uri',\n",
      "Step #1:                                      'value': 'gs://workshop-datasets/covertype/small'},\n",
      "Step #1:                                     {'name': 'eval-steps', 'value': '500'},\n",
      "Step #1:                                     {'name': 'train-steps', 'value': '5000'}],\n",
      "Step #1:                      'resource_references': [{'key': {'id': '59cae7e3-eb4a-4c04-bb71-1689808ecadd',\n",
      "Step #1:                                                       'type': 'PIPELINE'},\n",
      "Step #1:                                               'name': None,\n",
      "Step #1:                                               'relationship': 'OWNER'}]},\n",
      "Step #1:  'description': None,\n",
      "Step #1:  'error': None,\n",
      "Step #1:  'id': '59cae7e3-eb4a-4c04-bb71-1689808ecadd',\n",
      "Step #1:  'name': 'tfx_covertype_continuous_training-test2',\n",
      "Step #1:  'parameters': [{'name': 'pipeline-root',\n",
      "Step #1:                  'value': 'gs://dougkelly-sandbox-kubeflowpipelines-default/tfx_covertype_continuous_training-test2/{{workflow.uid}}'},\n",
      "Step #1:                 {'name': 'data-root-uri',\n",
      "Step #1:                  'value': 'gs://workshop-datasets/covertype/small'},\n",
      "Step #1:                 {'name': 'eval-steps', 'value': '500'},\n",
      "Step #1:                 {'name': 'train-steps', 'value': '5000'}],\n",
      "Step #1:  'url': None}\n",
      "Step #1: Please access the pipeline detail page at http://60ff837483ecde05-dot-us-central2.pipelines.googleusercontent.com/#/pipelines/details/59cae7e3-eb4a-4c04-bb71-1689808ecadd\n",
      "Step #1: Pipeline \"tfx_covertype_continuous_training-test2\" created successfully.\n",
      "Finished Step #1\n",
      "PUSH\n",
      "Pushing gcr.io/dougkelly-sandbox/lab-03-tfx-image:test2\n",
      "The push refers to repository [gcr.io/dougkelly-sandbox/lab-03-tfx-image]\n",
      "a2e1a045e6d9: Preparing\n",
      "32f161479668: Preparing\n",
      "5dadc0a09248: Preparing\n",
      "8fb12d3bda49: Preparing\n",
      "2471eac28ba8: Preparing\n",
      "674ba689ae71: Preparing\n",
      "4058ae03fa32: Preparing\n",
      "e3437c61d457: Preparing\n",
      "84ff92691f90: Preparing\n",
      "54b00d861a7a: Preparing\n",
      "c547358928ab: Preparing\n",
      "84ff92691f90: Preparing\n",
      "c4e66be694ce: Preparing\n",
      "47cc65c6dd57: Preparing\n",
      "674ba689ae71: Waiting\n",
      "4058ae03fa32: Waiting\n",
      "e3437c61d457: Waiting\n",
      "84ff92691f90: Waiting\n",
      "54b00d861a7a: Waiting\n",
      "c547358928ab: Waiting\n",
      "c4e66be694ce: Waiting\n",
      "47cc65c6dd57: Waiting\n",
      "8fb12d3bda49: Layer already exists\n",
      "2471eac28ba8: Layer already exists\n",
      "5dadc0a09248: Layer already exists\n",
      "674ba689ae71: Layer already exists\n",
      "4058ae03fa32: Layer already exists\n",
      "e3437c61d457: Layer already exists\n",
      "84ff92691f90: Layer already exists\n",
      "c547358928ab: Layer already exists\n",
      "54b00d861a7a: Layer already exists\n",
      "c4e66be694ce: Layer already exists\n",
      "47cc65c6dd57: Layer already exists\n",
      "32f161479668: Pushed\n",
      "a2e1a045e6d9: Pushed\n",
      "test2: digest: sha256:9b3d73e031d16ddb2f67314bf775e4775bc8d3d8877c920d17e0f10c437fa42e size: 3267\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                           IMAGES                                           STATUS\n",
      "acff2fc6-1cd8-43c7-b7e8-4682d8f3bcd7  2021-01-15T01:09:52+00:00  5M9S      gs://dougkelly-sandbox_cloudbuild/source/1610672991.449488-8203b5f3502b497abd585ba9e6a57b87.tgz  gcr.io/dougkelly-sandbox/lab-03-tfx-image:test2  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit . --config cloudbuild.yaml --substitutions {SUBSTITUTIONS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Setting up GitHub integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you integrate your CI/CD workflow with **GitHub**, using [Cloud Build GitHub App](https://github.com/marketplace/google-cloud-build). \n",
    "You will set up a trigger that starts the CI/CD workflow when a new tag is applied to the **GitHub** repo managing the  pipeline source code. You will use a fork of this repo as your source GitHub repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a fork of this repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. [Follow the GitHub documentation](https://help.github.com/en/github/getting-started-with-github/fork-a-repo) to fork this repo.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.  Create a Cloud Build trigger.**\n",
    "\n",
    "Connect the fork you created in the previous step to your Google Cloud project and create a trigger following the steps in the [Creating GitHub app trigger](https://cloud.google.com/cloud-build/docs/create-github-app-triggers) article. Use the following values on the **Edit trigger** form:\n",
    "\n",
    "|Field|Value|\n",
    "|-----|-----|\n",
    "|Name|[YOUR TRIGGER NAME]|\n",
    "|Description|[YOUR TRIGGER DESCRIPTION]|\n",
    "|Event| Tag|\n",
    "|Source| [YOUR FORK]|\n",
    "|Tag (regex)|.\\*|\n",
    "|Build Configuration|Cloud Build configuration file (yaml or json)|\n",
    "|Cloud Build configuration file location|/ workshops/tfx-caip-tf23/lab-03-tfx-cicd/cloudbuild.yaml|\n",
    "\n",
    "\n",
    "Use the following values for the substitution variables:\n",
    "\n",
    "|Variable|Value|\n",
    "|--------|-----|\n",
    "|_ENDPOINT|[Your inverting proxy host pipeline ENDPOINT]|\n",
    "|_TFX_IMAGE_NAME|lab-03-tfx-image|\n",
    "|_PIPELINE_NAME|tfx_covertype_continuous_training|\n",
    "|_PIPELINE_DSL|runner.py|\n",
    "|_DATA_ROOT_URI|gs://workshop-datasets/covertype/small|\n",
    "|_PIPELINE_FOLDER|workshops/tfx-caip-tf23/lab-03-tfx-cicd/pipeline|\n",
    "|_PYTHON_VERSION|3.7|\n",
    "|_RUNTIME_VERSION|2.3|\n",
    "|_USE_KFP_SA|False|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Trigger the build.**\n",
    "\n",
    "To start an automated build [create a new release of the repo in GitHub](https://help.github.com/en/github/administering-a-repository/creating-releases). Alternatively, you can start the build by applying a tag using `git`. \n",
    "```\n",
    "git tag [TAG NAME]\n",
    "git push origin --tags\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Verify triggered build in Cloud Build dashboard.**\n",
    "\n",
    "After you see the pipeline finish building on the Cloud Build dashboard, return to [AI Platform Pipelines](https://console.cloud.google.com/ai-platform/pipelines/clusters) in the console. Click `OPEN PIPELINES DASHBOARD` and view the newly deployed pipeline. Creating a release tag on GitHub will create a pipeline with the name `tfx_covertype_continuous_training-[TAG NAME]` while doing so from GitHub will create a pipeline with the name `tfx_covertype_continuous_training_github-[TAG NAME]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you walked through authoring a Cloud Build CI/CD workflow that automatically builds and deploys a TFX pipeline. You also integrated your TFX workflow with GitHub by setting up a Cloud Build trigger. In the next lab, you will walk through inspection of TFX metadata and pipeline artifacts created during TFX pipeline runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=-1>Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at [https://www.apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \\\"AS IS\\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the License for the specific language governing permissions and limitations under the License.</font>"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
